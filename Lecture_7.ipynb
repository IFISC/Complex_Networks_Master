{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef11f86-7f07-4ea1-9340-db1d83d47075",
   "metadata": {},
   "source": [
    "# Lecture 7: Networks that are not networks\n",
    "\n",
    "In this lecture we will learn about network representations of data that are not directly in a network format. The use of these methods will allow us to apply the tools of network theory to other areas, thus expanding the reach of complex network's concepts. One has to be aware that maybe taking this path is not the best for a given problem, as other tools might already exist that tackle our question. For other cases, the network perspective might yield additional insights into the system under study.\n",
    "\n",
    "We will cover three different cases:\n",
    "\n",
    "- Correlation networks.\n",
    "- Visibility graphs.\n",
    "- Lagrangian flow networks.\n",
    "\n",
    "## Correlation networks\n",
    "\n",
    "Correlation matrices are widely used across various disciplines, including financial economics, psychology, bioinformatics, neuroscience, and climate science, to analyze the pairwise similarity of temporally evolving signals and understand system interactions. The analysis of these matrices often involves well-established methods like principal component analysis (PCA) and factor analysis (FA), which simplify complex correlation data into interpretable components. Markowitz’s portfolio theory in finance and random matrix theory are other significant methods for this purpose. Additionally, newer methods such as detrended cross-correlation analysis and energy landscape analysis are emerging, especially in fields like neuroscience.\n",
    "\n",
    "In the last two decades, tools from network science and graph theory have been successfully applied to correlational data, converting correlation matrices into networks (correlation networks) where nodes represent elements and edges reflect the strength of correlations. This approach aims to uncover interaction patterns and rank nodes, providing insights that traditional methods might not reveal. However, constructing network representations from correlation matrices is challenging, and simple methods like thresholding can introduce problems, leading to the development of alternative methods.\n",
    "\n",
    "For a good introduction to correlation networks you can study [this paper](https://arxiv.org/abs/2311.09536). \n",
    "\n",
    "![Correlation network](./data/correlation_networks_color.png)\n",
    "\n",
    "### Examples\n",
    "\n",
    "- Psychological networks:\n",
    "    - Personality networks: Nodes represent personal traits or goals (e.g., being organized, wanting safety). Edges indicate conditional associations between traits/goals. Based on participant responses to questionnaires.\n",
    "    - Symptom Networks in Mental Health Research: Nodes are symptoms of conditions like depression, schizophrenia. Edges are associations between symptoms from participant responses. Useful for predicting psychopathology development, understanding comorbidity, and identifying intervention targets.\n",
    "    - Time-Varying/Within-Person Correlation Networks (Longitudinal Data): Reflect temporal symptom patterns, individual differences, and potential causal pathways. Provide insights into mental health patterns related to disorders.\n",
    "- Brain networks:\n",
    "    - Network Neuroscience: Focuses on studying brain networks to understand neural functions. Uses multivariate time series of neuronal signals from neuroimaging or electroencephalography. \n",
    "    - Functional Networks (Functional Connectivity): Constructed from correlation-based networks using neuronal time series data. \"Functional\" implies correlational, not implying direct anatomical connections. Typically involves voxels or spherical regions of interest (ROI) in the brain. (Different from anatomical connectivity networks).\n",
    "    - Functional MRI (fMRI): Uses blood-oxygen-level-dependent (BOLD) imaging. Correlation between fMRI time signals of voxels or ROIs, with frequency band adjustments to remove artifacts.\n",
    "    - EEG and MEG Networks: Functional connectivity calculated using methods suitable for oscillatory nature, like phase lag index or amplitude envelope correlation. \n",
    "    - Structural Covariance Networks: Edges defined by correlation/covariance of gray matter volume or cortical thickness between brain regions. Based on data from participants.\n",
    "    - Morphometric Similarity Networks: Variant of structural covariance networks. Uses various morphometric variables, not just cortical thickness. Allows for individual correlation network calculation.\n",
    "    - Neuroreceptor Similarity Networks: Edges represent correlation in receptor density between ROIs. Involves calculating a vector of neurotransmitter density for each ROI, followed by computing correlations.\n",
    "- Gene co-expression networks:\n",
    "    - Gene Co-Expression Networks: Used in network biology or network medicine to analyze interactions among genes. Constructed as correlation networks based on gene expression data from samples (typically human or animal).\n",
    "    - Network Analysis in Gene Studies: Co-expression calculated as sample correlation between gene pairs, forming a correlation matrix. Networks transformed from these matrices are analyzed using methods like community detection to associate genes with phenotypes, like diseases. Useful for gene screening, identifying biomarkers, and therapeutic targets.\n",
    "    - Tissue-to-Tissue (TTC) Co-Expression Networks: Bipartite networks where nodes are gene-tissue pairs. Edges represent sample correlations between genes in different tissues, highlighting cross-tissue gene co-expression.\n",
    "- Metabolite networks.\n",
    "- Microbiome networks: typically co-occurrence networks.\n",
    "- Disease networks.\n",
    "- Financial correlation networks.\n",
    "- Bibliometric networks.\n",
    "- Climate networks.\n",
    "\n",
    "#### Brain functional networks\n",
    "\n",
    "One of the first papers proposing the use of functional networks in the brain uncovered that the topology of brain fuctional networks is scale-free. You can check the paper [here](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.94.018102).\n",
    "\n",
    "![Brain functional network](./data/brain_functional_network.png)\n",
    "\n",
    "#### Space use in a city from telephone data\n",
    "\n",
    "Another interesting use can be found in [this paper](https://royalsocietypublishing.org/doi/10.1098/rsos.150449), where geolocated telephone use was mapped into a network of spatial locations. This network can then be studied with a community detection algorithm, which will cluster different regions into groups of similarly behaving spatiel locations.\n",
    "\n",
    "![City land use](./data/city_land_use_lenormand.png)\n",
    "\n",
    "They found 4 groups of spatial locations:\n",
    "\n",
    "1. Residential (red), which is characterized by low activities from 8am to 5 − 6pm. For the cells composing this group, the activity peaks around 7 − 8am and during the evening. In the weekend, the activity is almost constant except for the night hours;\n",
    "2. Business (blue), where the activity is significantly higher during the weekdays than during the weekends. Furthermore, it concentrates from 9am to 6 − 7pm. This land use designation can be related to a wide range of commercial, retail, service and office uses; \n",
    "3. Logistics/Industry (cyan), where, as for Business, the activity is higher during the weekdays. We observe a large peak between 5am and 7am followed by a smaller peak around 3pm. This cluster can be related to transport and distribution of goods: for example, ”Mercamadrid” (the largest distribution area of Madrid) belong to this cluster;\n",
    "4. Nightlife (orange), which is characterized by high activity during the night hours (1am-4am), especially during the weekends. During the weekdays, these areas show higher activity between 9am and 6pm, as for the Business cluster, which may be hinting a certain level of mixing in the land use. Some examples of this category are the ”Gran Via” in Madrid and the ”Ramblas” of Barcelona where abound theatres, restaurants and pubs mixed with offices and shops. This is typically the smallest cluster of the four in number of cells.\n",
    "\n",
    "![Average actievities aliong the week for each land use cluster](./data/land_clusters.png)\n",
    "\n",
    "### Correlation and covariance matrices\n",
    "\n",
    "The network is constructed from a correlation matrix. So first we have to calculate the correlation matrix. Imagine we have N nodes. The number of parameters in the correlation matrix that we need to calculate are N(N-1)/2 (same as the number of edges in an undirected complete graph). We do so by correlating a vector of size L that is associated to each node with the vector of another node. In particular if L < N the covariance matrix will be singular (although the real C is typically non-singular). Typically one will like to use some regularization technique in order not to need to estimate so many parameters. \n",
    "\n",
    "Another characteristic we might encounter is that correlations induce an euclidean distance space and this, at the same time, induces a high number of triangles in the data.\n",
    "\n",
    "![Correlation networks](./data/correlation_networks.png)\n",
    "\n",
    "### Thresholding and dichotomization\n",
    "\n",
    "1. **Thresholding Method**: This approach to network generation from correlation matrices is straightforward. A threshold value θ is set, and an unweighted edge between two nodes (i, j) is established if the Pearson correlation ρij is equal to or exceeds θ. The method allows for two variations: creating an unweighted network by normalizing all edge weights to 1, or forming a weighted network that retains the original weights of the correlations. The choice between these two depends on the specific requirements of the analysis.\n",
    "\n",
    "2. **Dichotomizing (or Binarizing)**: This process is widely used in various research areas, though it is often discouraged due to several drawbacks. The primary challenge is the lack of a standard method for selecting the appropriate threshold value, which can significantly impact the results of the network analysis. Different approaches to thresholding, such as absolute and proportional thresholding, introduce their own sets of biases and potential errors, including the risk of false positives and negatives in the network.\n",
    "\n",
    "3. **False Positives in Correlation Networks**: One of the key problems in correlation networks is the inability to distinguish between direct and indirect effects, leading to false positives. This issue arises because correlations are transitive, meaning that if two nodes i and j are both strongly correlated with a third node k, they will appear to be correlated with each other even if there is no direct interaction. This transitivity inflates the apparent correlation between nodes, making it difficult to discern actual direct relationships.\n",
    "\n",
    "4. **Mitigating Thresholding Problems**: To address the issues associated with thresholding, various methods have been proposed. One approach involves using a range of threshold values and integrating the results from these different thresholds. Another strategy is to determine the threshold value based on an optimization criterion, balancing factors like network efficiency and edge density. Alternative methods include using the maximal spanning tree, the planar maximally filtered graph, or the nearest neighbor graph approach. These methods aim to retain only the most relevant and statistically significant edges, thereby creating a more meaningful network representation.\n",
    "\n",
    "5. **Challenges with Thresholding**: Despite the efforts to mitigate its problems, thresholding inherently has several limitations. It tends to inflate the number of triangles and short cycles in the network, which can misrepresent the true nature of the network's structure. Moreover, thresholding discards valuable information contained in the values of the correlation coefficients, as it reduces the nuances of correlation strengths to a binary presence or absence of edges. Additionally, selecting an appropriate threshold range remains a non-trivial challenge, adding complexity to the network construction process.\n",
    "\n",
    "### Weighted networks\n",
    "\n",
    "1. **Use of Weighted Networks**: To circumvent the arbitrary choice of threshold values and the loss of information in dichotomizing, using weighted networks is proposed. In these networks, the edge weight is the pairwise correlation value. This approach is favored because it retains more information from the original correlation matrix and is compatible with many network analysis methods.\n",
    "\n",
    "2. **Handling Negative Edge Weights**: In weighted networks, negative edge weights pose a challenge. Two common solutions are employed: using the absolute value of the correlation coefficient as the edge weight or only considering positively weighted edges. While these methods dismiss some information (like the sign or magnitude of negative correlations), they simplify the network for analysis and are widely adopted in practice.\n",
    "\n",
    "3. **Problems with Weighted Networks**: Despite their advantages, weighted networks share the issue of false positives due to indirect interactions, similar to unweighted networks. Additionally, by including all levels of correlation, even those close to zero, weighted networks can increase the uncertainty and complexity of network analysis.\n",
    "\n",
    "4. **Thresholding Methods in Statistics**: In statistics, thresholding operations often produce weighted networks. Hard thresholding sets values below a certain threshold to zero, maintaining original values above it. Soft thresholding applies a continuous function to the values, creating a smoother transition. Both methods avoid dichotomization and are effective in creating weighted networks, each with its advantages in approximating true sparse covariance matrices.\n",
    "\n",
    "5. **Adaptive Thresholding**: This method uses thresholds specific to each node pair, improving approximation accuracy and convergence speed in numerical simulations. Adaptive thresholding's tailored approach offers a more refined way of constructing networks, potentially leading to more accurate and insightful network analysis results.\n",
    "\n",
    "6. **Deciding a value for the threshold**: There are several ways of deciding a value for the threshols. One can set, for example, a fixed value of the density of links. One could think about adding links in order and taking the value that first makes the network be in one component.\n",
    "\n",
    "7. **Forget about threshold for correlation: threshold for p-value**: Given an appropiate null model one can compute p-values associated to each edge and thus threshold based on significance.\n",
    "\n",
    "### Negative weights\n",
    "\n",
    "1. **Prohibition of Negative Edges**: In both unweighted and weighted correlation networks, negative edges are often avoided by either setting negative entries in the correlation matrix to zero or by using the absolute value of the pairwise correlation. This approach is mainly due to two reasons: difficulty in interpreting negative edges in some research areas, and the lack of established tools for analyzing networks with both positive and negative edges, known as signed networks. For example, while negative correlations in financial time series might be straightforward to interpret, in brain dynamics data, such as fMRI time series, the meaning of negative correlations can be less clear.\n",
    "\n",
    "2. **Potential Utility of Negative Edges**: Despite the challenges, negative edges can be informative, especially in community detection within networks. They can help identify different communities, as positive edges are often within a community while negative edges might ideally connect different ones. Some community detection algorithms for signed networks use this principle. Another approach is to analyze positive and negative edges separately and then combine the insights. For instance, modularity, a measure used in community detection, can be defined separately for positive and negative networks and then combined.\n",
    "\n",
    "3. **Signed Network Analysis Strategies**: While analysis of signed networks is still emerging, there are strategies specifically designed for them. These include using algorithms that exploit the unique characteristics of signed networks for community detection and separately analyzing networks composed of positive and negative edges. These methods, although developed for general signed networks, have been applied to brain correlation networks as well.\n",
    "\n",
    "4. **Nonparametric Weighted Stochastic Block Models**: This approach is useful for modeling correlation matrix data, particularly for signed weighted networks. It estimates the unweighted network structure and the weight of each edge within a unified Bayesian framework. To handle the edge weights, which in the case of correlation coefficients are confined between -1 and 1, an ad-hoc transformation is applied to map this range to (-∞, ∞). The model's effectiveness and the suitability of the transformation can be assessed using Bayesian model selection. This method allows for the analysis of negative correlation values and can determine the community structure, including its number and hierarchical organization, within the network.\n",
    "\n",
    "### Null models\n",
    "\n",
    "A critical practice in network analysis is to compare structural or dynamical measurements from a given network with those obtained from random networks. This comparison helps discern whether observed network properties are due to general structural features (like edge density or degree distributions) or other distinctive characteristics of the data. Many key findings in network science have emerged from this approach, often involving appropriate null models of networks.\n",
    "\n",
    "**Configuration Model as a Null Model**: The configuration model is a popular null model that maintains the degree of each node either exactly or on average. This model is used to quantify and discuss various network properties, such as network motifs, community structure, and core-periphery structures. It is particularly useful for exploring properties that are not simply outcomes of heterogeneous degree distribution. Nevertheless, standard configuration models are not suitable as null models for correlation networks, as they significantly differ from networks derived from purely random data. Instead, correlation networks require specific null models that account for the unique properties and dependencies inherent in correlation matrices.\n",
    "\n",
    "**Null Models Based on Spectral Properties**: One approach to null models focuses on the spectral properties of correlation matrices. For example, under the assumption of independent signals, the expected correlation matrix is the identity matrix. However, sample pairwise correlations measured from signals, even under the null hypothesis, will differ from the identity matrix, especially with a finite number of samples. Random matrix theory offers valuable null models in this regard, particularly for financial time series data analysis. The idea is to compare the correlation matrix to one that has kept only certain modes (the noisy ones, noisy ones plus the trend...)\n",
    "\n",
    "**Null Model based on the same data**: One typical way of producing a null model is to reshuffle the original data in different ways, so that certain characteristics are preserved and others are lost. In this way we can single out the characteristics that make the actual data 'special'.\n",
    "\n",
    "**Other correlation networks null models**: The H-Q-S algorithm  is an equivalent of the Erd˝os-R´enyi random graph in general network analysis. Specifically, given the covariance matrix, Csam, the H-Q-S algorithm generates random covariance matrices, C_HQS, under some constraints. Check [here](https://www.sciencedirect.com/science/article/pii/S0377221705006600) for more information. There is also a configuration model for covariance matrices, that can be consulted [here](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.98.012312) and  [here](https://royalsocietypublishing.org/doi/10.1098/rspa.2019.0578)\n",
    "\n",
    "### Practical example\n",
    "\n",
    "Now we will proceed with a practical example. We will use stock data from [Kaggle](https://www.kaggle.com/datasets/camnugent/sandp500/). You can find the data in the data folder, with the name 'all_stocks_5yr.csv'. We will read the file. Then we will keep only the first 50 companies and look for the correlations among all pairs. You can use whatever value you want for calculating the correlation: open, high, low, volume. In order to do the thresholding we will do in statistical significance. We want the p-value to be under 0.05. To calculate the p-value we will use reshufflings of the same data. Last we will visualize the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf171cb8-03c6-4a95-a816-9e3c1918f439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>15.07</td>\n",
       "      <td>15.12</td>\n",
       "      <td>14.63</td>\n",
       "      <td>14.75</td>\n",
       "      <td>8407500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>14.89</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.46</td>\n",
       "      <td>8882000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>14.45</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.10</td>\n",
       "      <td>14.27</td>\n",
       "      <td>8126000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>14.30</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.66</td>\n",
       "      <td>10259500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.99</td>\n",
       "      <td>31879900</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   open   high    low  close    volume Name\n",
       "0  2013-02-08  15.07  15.12  14.63  14.75   8407500  AAL\n",
       "1  2013-02-11  14.89  15.01  14.26  14.46   8882000  AAL\n",
       "2  2013-02-12  14.45  14.51  14.10  14.27   8126000  AAL\n",
       "3  2013-02-13  14.30  14.94  14.25  14.66  10259500  AAL\n",
       "4  2013-02-14  14.94  14.96  13.16  13.99  31879900  AAL"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "stocks_df = pd.read_csv('./data/all_stocks_5yr.csv')\n",
    "stocks_df = stocks_df.replace(np.nan,0)\n",
    "stocks_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b664f3f-4737-41ad-bc13-f933b3dd0e3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m i_open \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(i_open)\n\u001b[1;32m     21\u001b[0m j_open \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(j_open)\n\u001b[0;32m---> 22\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrcoef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj_open\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;241m>\u001b[39m corr:\n\u001b[1;32m     24\u001b[0m     pval \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/complex_networks/lib/python3.8/site-packages/numpy/lib/function_base.py:2845\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;129;01mor\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[1;32m   2842\u001b[0m     \u001b[38;5;66;03m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[1;32m   2843\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias and ddof have no effect and are deprecated\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   2844\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m-> 2845\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2847\u001b[0m     d \u001b[38;5;241m=\u001b[39m diag(c)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/complex_networks/lib/python3.8/site-packages/numpy/lib/function_base.py:2680\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2677\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2678\u001b[0m         w \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m aweights\n\u001b[0;32m-> 2680\u001b[0m avg, w_sum \u001b[38;5;241m=\u001b[39m \u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2681\u001b[0m w_sum \u001b[38;5;241m=\u001b[39m w_sum[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;66;03m# Determine the normalization\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/complex_networks/lib/python3.8/site-packages/numpy/lib/function_base.py:518\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[1;32m    515\u001b[0m     keepdims_kw \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims}\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeepdims_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m     scl \u001b[38;5;241m=\u001b[39m avg\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(a\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m/\u001b[39mavg\u001b[38;5;241m.\u001b[39msize)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/complex_networks/lib/python3.8/site-packages/numpy/core/_methods.py:182\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    180\u001b[0m ret \u001b[38;5;241m=\u001b[39m umr_sum(arr, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 182\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrue_divide\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munsafe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_float16_result \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m         ret \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(ret)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "names = list(set(stocks_df['Name']))\n",
    "N_names = 10\n",
    "N_runs = 100\n",
    "pval_thres = 0.05\n",
    "good_names = names[:N_names]\n",
    "corr_net = np.zeros((N_names,N_names))\n",
    "for i in range(N_names-1):\n",
    "    iname = good_names[i]\n",
    "    i_open = list(stocks_df[stocks_df['Name']==iname]['open'])\n",
    "    #print(i_open)\n",
    "    for j in range(i+1,N_names):\n",
    "        jname = good_names[j]\n",
    "        j_open = list(stocks_df[stocks_df['Name']==jname]['open'])\n",
    "        #print(j_open)\n",
    "        corr = np.corrcoef(i_open,j_open)\n",
    "        pval = 0\n",
    "        for irun in range(N_runs):\n",
    "            i_open = np.random.shuffle(i_open)\n",
    "            j_open = np.random.shuffle(j_open)\n",
    "            c = np.corrcoef(i_open,j_open)\n",
    "            if c > corr:\n",
    "                pval += 1\n",
    "        if pval < N_runs*pval_thres:\n",
    "            corr_net[i,j] = corr\n",
    "print(len(names))\n",
    "plt.imshow(corr_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f116255-0047-4ac5-bebe-9bf56c3277b3",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e3529-39a9-4568-b8b1-5313cad382ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b19a6e06-bca6-494b-920b-5ca8d6c9ccd8",
   "metadata": {},
   "source": [
    "## Visibility graphs\n",
    "\n",
    "### Network construction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903fafd-00dd-4754-8614-766207da5950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb810221-6daa-4220-ad77-7bb79edc0acb",
   "metadata": {},
   "source": [
    "### Recovering time-series properties from the visibility graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b4c06-7af2-40f7-b105-c40edae96a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6a23170-cc7b-4d5b-b8c9-aa7b2558e9fd",
   "metadata": {},
   "source": [
    "## Lagrangian flow networks\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38527bad-d7c2-4fdf-b441-825942e90b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "complex_networks",
   "language": "python",
   "name": "complex_networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
